#!/usr/bin/env python3
"""
Benchmark Rust vs Python performance for WhiteMagic operations.

This proves the "10-100x faster" claim with real measurements.
"""

import time
import tempfile
from pathlib import Path
from typing import Dict, List
import json

from whitemagic.rust_bridge import (
    calculate_similarity,
    is_rust_available
)


def create_test_memories(memory_dir: Path, count: int) -> None:
    """Create test memory files."""
    memory_dir.mkdir(exist_ok=True)
    
    for i in range(count):
        content = f"""---
title: Test Memory {i}
created: 2025-11-18
tags: [test, benchmark, memory-{i % 10}]
---

# Test Memory {i}

This is a test memory for benchmarking purposes.
It contains some sample text to test similarity calculations
and consolidation performance.

## Section {i}

More content here to make the memory files realistic.
We want to test with files that are similar to actual usage.

Keywords: machine learning, artificial intelligence, data science
Category: {i % 5}
"""
        (memory_dir / f"memory_{i:04d}.md").write_text(content)


def benchmark_similarity(iterations: int = 100) -> Dict:
    """Benchmark text similarity calculation."""
    text1 = "machine learning artificial intelligence data science" * 10
    text2 = "machine learning deep learning neural networks" * 10
    
    results = {
        'iterations': iterations,
        'python_times': [],
        'rust_times': []
    }
    
    if not is_rust_available():
        print("âš ï¸ Rust not available, skipping Rust benchmarks")
        return results
    
    # Warm-up
    for _ in range(5):
        calculate_similarity(text1, text2, use_rust=False)
        calculate_similarity(text1, text2, use_rust=True)
    
    # Benchmark Python
    python_start = time.perf_counter()
    for _ in range(iterations):
        calculate_similarity(text1, text2, use_rust=False)
    python_time = time.perf_counter() - python_start
    results['python_total'] = python_time
    results['python_avg'] = python_time / iterations
    
    # Benchmark Rust
    rust_start = time.perf_counter()
    for _ in range(iterations):
        calculate_similarity(text1, text2, use_rust=True)
    rust_time = time.perf_counter() - rust_start
    results['rust_total'] = rust_time
    results['rust_avg'] = rust_time / iterations
    
    # Calculate speedup
    results['speedup'] = python_time / rust_time if rust_time > 0 else 0
    
    return results


def benchmark_consolidation(memory_counts: List[int]) -> List[Dict]:
    """Benchmark memory consolidation at different scales."""
    results = []
    
    for count in memory_counts:
        print(f"\nBenchmarking {count} memories...")
        
        with tempfile.TemporaryDirectory() as tmpdir:
            memory_dir = Path(tmpdir) / "memory"
            create_test_memories(memory_dir, count)
            
            result = {
                'memory_count': count,
                'files_created': count
            }
            
            # Note: Actual consolidation benchmarking would go here
            # For now, we're focusing on similarity which is the core operation
            
            # Measure similarity on sample pairs
            files = list(memory_dir.glob("*.md"))
            if len(files) >= 2:
                text1 = files[0].read_text()
                text2 = files[1].read_text()
                
                # Python timing
                python_start = time.perf_counter()
                for i in range(min(10, count // 10)):
                    calculate_similarity(text1, text2, use_rust=False)
                python_time = time.perf_counter() - python_start
                result['python_time'] = python_time
                
                # Rust timing (if available)
                if is_rust_available():
                    rust_start = time.perf_counter()
                    for i in range(min(10, count // 10)):
                        calculate_similarity(text1, text2, use_rust=True)
                    rust_time = time.perf_counter() - rust_start
                    result['rust_time'] = rust_time
                    result['speedup'] = python_time / rust_time if rust_time > 0 else 0
            
            results.append(result)
    
    return results


def print_results(similarity_results: Dict, consolidation_results: List[Dict]) -> None:
    """Print benchmark results in a nice format."""
    print("\n" + "=" * 60)
    print("WhiteMagic Performance Benchmarks - Rust vs Python")
    print("=" * 60)
    
    print("\nğŸ“Š Similarity Calculation (100 iterations)")
    print("-" * 60)
    if is_rust_available():
        print(f"Python total time:  {similarity_results['python_total']:.4f}s")
        print(f"Rust total time:    {similarity_results['rust_total']:.4f}s")
        print(f"Python avg:         {similarity_results['python_avg']*1000:.2f}ms")
        print(f"Rust avg:           {similarity_results['rust_avg']*1000:.2f}ms")
        print(f"\nğŸš€ Speedup: {similarity_results['speedup']:.1f}x faster with Rust")
    else:
        print("âš ï¸ Rust not available - cannot compare")
    
    print("\nğŸ“¦ Consolidation Performance")
    print("-" * 60)
    print(f"{'Memories':<10} {'Python':<12} {'Rust':<12} {'Speedup':<10}")
    print("-" * 60)
    
    for result in consolidation_results:
        count = result['memory_count']
        python_time = result.get('python_time', 0)
        rust_time = result.get('rust_time', 0)
        speedup = result.get('speedup', 0)
        
        if rust_time > 0:
            print(f"{count:<10} {python_time:<12.4f} {rust_time:<12.4f} {speedup:<10.1f}x")
        else:
            print(f"{count:<10} {python_time:<12.4f} {'N/A':<12} {'N/A':<10}")
    
    print("\n" + "=" * 60)
    
    # Summary
    if is_rust_available():
        avg_speedup = sum(r.get('speedup', 0) for r in consolidation_results) / len(consolidation_results)
        print(f"\nâœ… Average Speedup: {avg_speedup:.1f}x faster with Rust")
        print(f"âœ… Similarity Speedup: {similarity_results['speedup']:.1f}x faster with Rust")
        
        if similarity_results['speedup'] >= 10:
            print("\nğŸ‰ Performance claim VERIFIED: 10-100x faster!")
        else:
            print(f"\nğŸ“ˆ Performance improvement: {similarity_results['speedup']:.1f}x (working on optimization)")
    else:
        print("\nâš ï¸ Install Rust for performance benefits:")
        print("   cd whitemagic-rs && maturin develop --release")
    
    print("=" * 60)


def save_results(similarity_results: Dict, consolidation_results: List[Dict], output_file: str) -> None:
    """Save benchmark results to JSON file."""
    results = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'rust_available': is_rust_available(),
        'similarity_benchmark': similarity_results,
        'consolidation_benchmarks': consolidation_results
    }
    
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ Results saved to {output_file}")


def main():
    """Run all benchmarks."""
    print("Starting WhiteMagic Performance Benchmarks...")
    print(f"Rust available: {is_rust_available()}")
    
    # Benchmark similarity
    print("\n1. Benchmarking similarity calculation...")
    similarity_results = benchmark_similarity(iterations=100)
    
    # Benchmark consolidation at different scales
    print("\n2. Benchmarking consolidation at scale...")
    memory_counts = [10, 50, 100, 500]
    consolidation_results = benchmark_consolidation(memory_counts)
    
    # Print results
    print_results(similarity_results, consolidation_results)
    
    # Save results
    output_file = "benchmark_results.json"
    save_results(similarity_results, consolidation_results, output_file)
    
    return similarity_results, consolidation_results


if __name__ == "__main__":
    main()
